{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabgen.definitions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_fields = [col for col in pd.read_csv(Path.FEATURE_FILE, nrows=0).columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the probabilities from preprocessing\n",
    "prob_read = [(np.fromstring(kk, dtype=np.float32), vv) for kk, vv in np.load('./data/probabilities_1.npy').tolist().items()]\n",
    "# [p[1] for p in prob_read]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correlation_coefficient</th>\n",
       "      <th>fret_25%</th>\n",
       "      <th>fret_50%</th>\n",
       "      <th>fret_75%</th>\n",
       "      <th>fret_max</th>\n",
       "      <th>fret_mean</th>\n",
       "      <th>fret_min</th>\n",
       "      <th>fret_range</th>\n",
       "      <th>fret_std</th>\n",
       "      <th>heuristic_all_zero</th>\n",
       "      <th>...</th>\n",
       "      <th>next_pitches_std</th>\n",
       "      <th>string_25%</th>\n",
       "      <th>string_50%</th>\n",
       "      <th>string_75%</th>\n",
       "      <th>string_max</th>\n",
       "      <th>string_mean</th>\n",
       "      <th>string_min</th>\n",
       "      <th>string_range</th>\n",
       "      <th>string_std</th>\n",
       "      <th>probs_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.145094</td>\n",
       "      <td>2.241250</td>\n",
       "      <td>2.381500</td>\n",
       "      <td>2.560750</td>\n",
       "      <td>2.752000</td>\n",
       "      <td>2.406333</td>\n",
       "      <td>2.082000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.322181</td>\n",
       "      <td>0.391000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.610300</td>\n",
       "      <td>3.214250</td>\n",
       "      <td>3.416000</td>\n",
       "      <td>3.613250</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>3.412667</td>\n",
       "      <td>3.011000</td>\n",
       "      <td>0.799000</td>\n",
       "      <td>0.353363</td>\n",
       "      <td>0.973000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.433173</td>\n",
       "      <td>3.154947</td>\n",
       "      <td>3.227014</td>\n",
       "      <td>3.328431</td>\n",
       "      <td>3.502965</td>\n",
       "      <td>3.209194</td>\n",
       "      <td>3.110458</td>\n",
       "      <td>1.700586</td>\n",
       "      <td>0.837655</td>\n",
       "      <td>0.488219</td>\n",
       "      <td>...</td>\n",
       "      <td>2.458266</td>\n",
       "      <td>1.066265</td>\n",
       "      <td>1.083336</td>\n",
       "      <td>1.177497</td>\n",
       "      <td>1.332545</td>\n",
       "      <td>1.080991</td>\n",
       "      <td>1.139376</td>\n",
       "      <td>1.215762</td>\n",
       "      <td>0.535183</td>\n",
       "      <td>0.120140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.117851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.681787</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.984838</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.160247</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       correlation_coefficient     fret_25%     fret_50%     fret_75%  \\\n",
       "count              1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean                 -0.145094     2.241250     2.381500     2.560750   \n",
       "std                   0.433173     3.154947     3.227014     3.328431   \n",
       "min                  -1.000000     0.000000     0.000000     0.000000   \n",
       "25%                   0.000000     0.000000     0.000000     0.000000   \n",
       "50%                   0.000000     1.000000     1.000000     1.000000   \n",
       "75%                   0.000000     3.000000     3.000000     3.000000   \n",
       "max                   1.000000    12.000000    12.000000    12.000000   \n",
       "\n",
       "          fret_max    fret_mean     fret_min   fret_range     fret_std  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      2.752000     2.406333     2.082000     0.670000     0.322181   \n",
       "std       3.502965     3.209194     3.110458     1.700586     0.837655   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000     1.000000     1.000000     0.000000     0.000000   \n",
       "75%       3.000000     3.000000     3.000000     0.250000     0.117851   \n",
       "max      12.000000    12.000000    12.000000    11.000000     5.500000   \n",
       "\n",
       "       heuristic_all_zero     ...       next_pitches_std   string_25%  \\\n",
       "count         1000.000000     ...            1000.000000  1000.000000   \n",
       "mean             0.391000     ...               1.610300     3.214250   \n",
       "std              0.488219     ...               2.458266     1.066265   \n",
       "min              0.000000     ...               0.000000     0.000000   \n",
       "25%              0.000000     ...               0.000000     3.000000   \n",
       "50%              0.000000     ...               0.000000     3.250000   \n",
       "75%              1.000000     ...               3.681787     3.750000   \n",
       "max              1.000000     ...              10.984838     6.000000   \n",
       "\n",
       "        string_50%   string_75%   string_max  string_mean   string_min  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      3.416000     3.613250     3.810000     3.412667     3.011000   \n",
       "std       1.083336     1.177497     1.332545     1.080991     1.139376   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       3.000000     3.000000     3.000000     3.000000     3.000000   \n",
       "50%       3.500000     4.000000     4.000000     3.500000     3.000000   \n",
       "75%       4.000000     4.500000     5.000000     4.000000     3.000000   \n",
       "max       6.000000     6.000000     6.000000     6.000000     6.000000   \n",
       "\n",
       "       string_range   string_std      probs_1  \n",
       "count   1000.000000  1000.000000  1000.000000  \n",
       "mean       0.799000     0.353363     0.973000  \n",
       "std        1.215762     0.535183     0.120140  \n",
       "min        0.000000     0.000000     0.006667  \n",
       "25%        0.000000     0.000000     1.000000  \n",
       "50%        0.000000     0.000000     1.000000  \n",
       "75%        2.000000     0.816497     1.000000  \n",
       "max        5.000000     2.160247     1.000000  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(Path.FEATURE_FILE, nrows=1000)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitches_mean</th>\n",
       "      <th>fret_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-12.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-15.666667</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>-1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-4.500000</td>\n",
       "      <td>-0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-7.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11.500000</td>\n",
       "      <td>-3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-11.333333</td>\n",
       "      <td>-1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.666667</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-5.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-3.333333</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11.500000</td>\n",
       "      <td>-3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>-12.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>-1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>-19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>-14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>-3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>-8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>-4.000000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>-9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>-2.750000</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>-1.750000</td>\n",
       "      <td>-0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pitches_mean  fret_mean\n",
       "0       62.000000   3.000000\n",
       "1        2.000000  -3.000000\n",
       "2       -2.000000   3.000000\n",
       "3       -2.000000  -2.000000\n",
       "4      -12.000000  -0.500000\n",
       "5        9.000000   1.500000\n",
       "6       -0.333333   0.000000\n",
       "7      -15.666667  -1.000000\n",
       "8       16.000000   1.000000\n",
       "9       -4.000000   1.000000\n",
       "10       6.000000  -1.666667\n",
       "11      -4.500000  -0.083333\n",
       "12       0.500000   1.250000\n",
       "13      -1.000000  -1.000000\n",
       "14       6.000000  -0.500000\n",
       "15      -7.500000   2.000000\n",
       "16      11.500000  -3.000000\n",
       "17      -2.000000   3.000000\n",
       "18      -2.000000  -2.000000\n",
       "19     -10.000000  -1.000000\n",
       "20       7.000000   2.000000\n",
       "21      -0.666667  -0.333333\n",
       "22     -11.333333  -1.666667\n",
       "23      12.000000   2.000000\n",
       "24       1.666667  -1.000000\n",
       "25      -5.333333   1.000000\n",
       "26      -3.333333  -2.000000\n",
       "27       5.000000   0.000000\n",
       "28      -2.500000   3.000000\n",
       "29      11.500000  -3.000000\n",
       "..            ...        ...\n",
       "594    -12.000000  -0.500000\n",
       "595      9.000000   1.500000\n",
       "596     -2.000000   0.500000\n",
       "597      5.000000  -1.500000\n",
       "598    -19.000000   0.000000\n",
       "599     26.000000   2.000000\n",
       "600    -14.000000   0.000000\n",
       "601      4.000000  -1.000000\n",
       "602     -6.000000  -0.500000\n",
       "603     -1.000000  -1.500000\n",
       "604      5.000000   0.000000\n",
       "605     -3.000000   2.000000\n",
       "606      8.000000  -1.000000\n",
       "607     -8.000000   1.000000\n",
       "608      3.000000  -2.000000\n",
       "609     -4.000000   1.500000\n",
       "610     -1.000000  -1.500000\n",
       "611      5.000000   0.000000\n",
       "612     -5.000000   0.000000\n",
       "613      9.000000   0.000000\n",
       "614     -9.000000   0.000000\n",
       "615      5.000000   0.000000\n",
       "616     -2.750000   1.250000\n",
       "617      1.500000   0.250000\n",
       "618     -1.250000  -1.500000\n",
       "619      1.000000   1.000000\n",
       "620      0.000000   0.000000\n",
       "621     -1.750000  -0.250000\n",
       "622      1.250000   0.000000\n",
       "623      4.250000   0.750000\n",
       "\n",
       "[624 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_one = pd.read_csv('./data/training_features/1229701 - Passenger - Let Her Go (guitar pro).gp5.mscx.csv')\n",
    "data_one[['pitches_mean', 'fret_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[['string_mean', 'fret_mean', 'string_std', 'fret_std', 'probs_1', 'probs_2']].to_csv(Path.FEATURE_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[['string_mean', 'fret_mean', 'string_std', 'fret_std', 'probs_1', 'probs_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-77df2c706461>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'likelihood'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'probs_1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'probs_2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'log_likelhihood'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'likelihood'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data['likelihood'] = data['probs_1'] * data['probs_2']\n",
    "data['log_likelhihood'] = -np.log(data['likelihood'])\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Older Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_models(X,Y):\n",
    "    from sklearn.model_selection import KFold\n",
    "    \n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "    # define models to evaluate\n",
    "    models = [\n",
    "        LinearRegression(),\n",
    "        #KNeighborsRegressor(),\n",
    "        MLPRegressor(hidden_layer_sizes=(100,50,25)),\n",
    "        #MLPRegressor(hidden_layer_sizes=(100,50,25),activation='logistic'),\n",
    "    ]\n",
    "\n",
    "    # start empty arrays for models\n",
    "    scores = {}\n",
    "    for model in models:\n",
    "        scores[str(model)] = []\n",
    "\n",
    "    # evaluate with CV\n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    for train, valid in tqdm(kf.split(X,Y),desc='Cross-validating',total=n_splits):\n",
    "        for model in models:\n",
    "            model.fit(X.iloc[train],Y.iloc[train])\n",
    "            scores[str(model)].append( model.score(X.iloc[valid],Y.iloc[valid]) )\n",
    "\n",
    "    scores = pd.DataFrame(scores)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validating:   0%|          | 0/5 [00:00<?, ?it/s]/afs/inf.ed.ac.uk/user/s16/s1675946/virtualenvs/iaml_env/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1266: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "Cross-validating: 100%|██████████| 5/5 [01:16<00:00, 15.49s/it]\n"
     ]
    }
   ],
   "source": [
    "scores = evaluate_models(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)</th>\n",
       "      <td>0.051215</td>\n",
       "      <td>0.002322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\\n       beta_2=0.999, early_stopping=False, epsilon=1e-08,\\n       hidden_layer_sizes=(100, 50, 25), learning_rate='constant',\\n       learning_rate_init=0.001, max_iter=200, momentum=0.9,\\n       nesterovs_momentum=True, power_t=0.5, random_state=None,\\n       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\\n       verbose=False, warm_start=False)</th>\n",
       "      <td>0.126534</td>\n",
       "      <td>0.011473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        mean       std\n",
       "LinearRegression(copy_X=True, fit_intercept=Tru...  0.051215  0.002322\n",
       "MLPRegressor(activation='relu', alpha=0.0001, b...  0.126534  0.011473"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.describe().T[['mean','std']]#,'min','max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try again with PCA\n",
    "#from sklearn.decomposition import KernelPCA\n",
    "from sklearn.decomposition.incremental_pca import IncrementalPCA\n",
    "\n",
    "pca = IncrementalPCA().fit(X)\n",
    "\n",
    "(X_pca,X_pca_test) = train_test_split(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFkCAYAAACq4KjhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x598bb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at PCA components\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot( np.cumsum(pca.explained_variance_ratio_) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keeping variance: 0.994182832311\n"
     ]
    }
   ],
   "source": [
    "# reduce dimensionality\n",
    "pca_components = 40\n",
    "X_pca = pd.DataFrame( pca.transform(X)[:,:pca_components] )\n",
    "print 'keeping variance: {}'.format(np.sum(pca.explained_variance_ratio_[:pca_components]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validating: 100%|██████████| 5/5 [07:40<00:00, 87.11s/it]\n"
     ]
    }
   ],
   "source": [
    "scores_pca = evaluate_models(X_pca,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)</th>\n",
       "      <td>0.067186</td>\n",
       "      <td>0.006516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\\n       beta_2=0.999, early_stopping=False, epsilon=1e-08,\\n       hidden_layer_sizes=(100, 50, 25), learning_rate='constant',\\n       learning_rate_init=0.001, max_iter=200, momentum=0.9,\\n       nesterovs_momentum=True, power_t=0.5, random_state=None,\\n       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\\n       verbose=False, warm_start=False)</th>\n",
       "      <td>0.058670</td>\n",
       "      <td>0.024829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        mean       std\n",
       "LinearRegression(copy_X=True, fit_intercept=Tru...  0.067186  0.006516\n",
       "MLPRegressor(activation='relu', alpha=0.0001, b...  0.058670  0.024829"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_pca.describe().T[['mean','std']]#,'min','max']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
